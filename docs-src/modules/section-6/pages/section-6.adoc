:imagesdir: ../assets/images

[.text-justify]
:Figure-caption!:

== SECTION 6. BASIC SEARCH ALGORITHMS

Searching is one of the most important algorithms for processing data
structures. Search algorithms are designed to check the presence of an
element or extract an element from any data structure in which it is
stored. More strictly, the search problem can be formulated as follows:
find one or more elements in the set, and the elements sought must have
a certain property. This property can be absolute or relative. A
relative property characterizes an element with respect to other
elements: for example, a minimum element in a set of numbers.

There are a lot of search algorithms. Their complexity varies from
simple sequential search algorithms, in extremely efficient but limited
binary search algorithms. Of particular note are algorithms based on the
presentation of a core set of data in a different, more searchable form,
which are used in real-world applications for processing data sets in
huge databases.

There is no single algorithm to solve the search problems. Some of the algorithms run faster than others, but require
additional RAM to run. Others run very quickly, but can only be used for
pre-sorted arrays. At the same time, the analysis of search algorithms
is somewhat different from sorting algorithms. In particular, there is
no sustainability problem for them. In this case there may be situations
that require introduction of new criteria of complexity and its
assessment. In general, all algorithms are reduced to
following steps :

[arabic]
. establishing the property of the elements of the source set; in most
cases, these are the values of the elements;
. match the value of the element with the reference property (for
absolute properties) or compare the properties of the two elements (for
relative properties);
. traversing the elements of the set.

In principle, search algorithms differ between search methods and search
strategies. Based on the type of search operation, these algorithms are
usually classified in two categories:

_Sequential Search:_ The list or array is performed sequentially and
each element is checked.

_Interval search:_ These algorithms are specifically designed to search
in sorted data structures. These types of search algorithms are much
more efficient than linear search because they repeatedly target the
center of the search structure and divide the search space in half.

This section examines the primary algorithms used for searching data structures. 
To enhance the understanding of the practical applications of these algorithms, 
DRAKON-diagrams are provided along with assessments of their time and space complexity.

.List of Figures
[cols="1,3,4"]
|===
| Figure | Title | Description

| 6.1
| Linear Search
| DRAKON-diagram of the Linear Search Algorithm

| 6.2
| Sorted Data Search
| DRAKON-diagram of the Search in a Sorted Array

| 6.3
| Binary Search
| DRAKON-diagram of the Binary Search Algorithm

| 6.4a
| Main Function
| Entry Point for Linked List Operations

| 6.4b
| PushFront / PushBack
| Adding New Items to the List

| 6.4c
| SearchData
| Searching for an Element in a Linked List

| 6.4d
| RemoveVal
| Deleting a Node by Value

| 6.4e
| PushVal / NodeWithVal
| Inserting by Value and Locating Node by Value

| 6.4f
| RemoveDupli
| Removing Duplicate Nodes

| 6.5a
| Hash Table Creation
| DRAKON-diagram of the `createHashTable` Function

| 6.5b
| Node Creation
| DRAKON-diagram of the `createNode` Function

| 6.5c
| Hash Table Bucket
| Visualization of a Bucket with Linked List (Chaining)

| 6.6a
| Hash Table Insertion
| DRAKON-diagram of the Hash Insertion Algorithm

| 6.6b
| Hash Table Search
| DRAKON-diagram of the Hash Search Algorithm

| 6.6c
| Hash Table Traversal
| DRAKON-diagram of the Hash Traversal Algorithm

| 6.6d
| Hash Table Deletion
| DRAKON-diagram of the Hash Deletion Algorithm
|===

NOTE
All illustrations in this section are provided in the **SVG** format.  
Click on any image to open it in a separate window for detailed viewing.


=== 6.1. Linear data searching

a). Linear searching of input data

In the case of a linear search of an element in an unordered dataset,
for example, in an array or in a slice, the simplest algorithm is to
view all elements until the desired value is found (Figure 6.1).

//image::{imagesdir}/Fig6_1_searchElement_v2.png[width=75%]

image::{imagesdir}/Fig6_1_searchElement.png[width=50%, link="{imagesdir}/Fig6_1_searchElement.svg", window="_blank"]

[.text-center]
Figure 6.1. DRAKON-diagram of the Linear Search Algorithm
              
This algorithm is not very effective, but it works on arbitrary
collections. _Time complexity:_ O(n). In the worst case (the desired
element is in the last position) to find the element you need to pass
all the elements cut. Here "n" is the size of the cut. additional
memory. In principle, another worst case is the absence of the necessary
element. _Space complexity:_ O(1). No additional memory is required to
accommodate the slice.

b). Linear search of sorted data in slice

If the elements of the dataset are sorted by ascending or descending,
finding the desired element is much more efficient than in an unordered
linear search. Because in many cases, you don’t have to go through the
whole list. For example, when an item with a higher value is discovered
as a result of passing through an increasing sorted list, the search is
stopped. This approach saves time and increases productivity. Figure
6.2. shows the DRAKON-diagram of this algorithm.

//image::{imagesdir}/Fig6_2_dataSorted.png[width=75%]
image::{imagesdir}/Fig6_2_dataSorted.png[width=50%, link="{imagesdir}/Fig6_2_dataSorted.svg", window="_blank"]


[.text-center]
Figure 6.2. DRAKON-diagram of the Search in a Sorted Array


=== 6.2. Binary search for data in a sorted data

Binary search is performed as follows:

[arabic]
. Specifies the value of the element in the middle of the data
structure. The resulting value is compared to the value you are looking
for.
. If the search value is less than the value of the means, the search is
carried out in the first half of the elements, otherwise - in the
second.3. The search is simply that the value of the middle element in
the selected half is again determined and compared to the key.
. The process continues until an item with the search value is found or
the search interval is empty.

The DRAKON-diagram of the binary search algorithm is represented in
Figure 6.3. 

//image::{imagesdir}/Fig6_3_searchValue.png[width=75%]
image::{imagesdir}/Fig6_3_searchValue.png[width=50%, link="{imagesdir}/Fig6_3_searchValue.svg", window="_blank"]

[.text-center]
Figure 6.3. DRAKON-diagram of Binary Search algorithm

_Time complexity_ of binary search algorithm belongs to class O(log n).
The way to interpret this is that the asymptotic increase in the time
taken by a function to perform a given input set of size n will not
exceed log n. _Space complexity_: O(1). That is, no extra space
required.

=== 6.3. Searching in Single-Linked List

There are three possibilities for a single-linked list. First, the
desired value is missing from the list, second, the desired value is
encountered once and, third, the desired value is encountered
repeatedly. You can also set the task of removing duplicates, i.e.,
nodes that are redundant. To solve these problems it is necessary to
create a Single-Linked List, the items of which contain values "Smith
A.", "Shafler B.”, "Wiley D.", "Brown G.", "Black H.". In this list you
should delete the entry " Brown G." and then add a new entry "Singer B."
placing it after the entry "Wiley D.". After that, you should delete the
duplicates of the entry " Shafler B." leaving only one. The
corresponding DRAKON-diagrams are presented in Figures 6.4 a,b,c,d,e,f

//image::{imagesdir}/Fig6_4a_main.png[width=75%]
image::{imagesdir}/Fig6_4a_main.png[width=50%, link="{imagesdir}/Fig6_4a_main.svg", window="_blank"]

[.text-center]
a). Function `main()`

//image::{imagesdir}/Fig6_4b_pushFront.png[width=75%]
image::{imagesdir}/Fig6_4b_pushFront.png[width=50%, link="{imagesdir}/Fig6_4b_pushFront.svg", window="_blank"]

//image::{imagesdir}/Fig6_4b_pushBack.png[width=75%]
image::{imagesdir}/Fig6_4b_pushBack.png[width=50%, link="{imagesdir}/Fig6_4b_pushBack.svg", window="_blank"]

[.text-center]
b). Function of pushing new items (`pushFront(list,val) and pushback(list,val)`)

//image::{imagesdir}/Fig6_4c_searchData.png[width=75%]
image::{imagesdir}/Fig6_4c_searchData.png[width=50%, link="{imagesdir}/Fig6_4c_searchData.svg", window="_blank"]

[.text-center]
c). Function of searching `searchData(val)`

//image::{imagesdir}/Fig6_4d_removeVal.png[width=75%]
image::{imagesdir}/Fig6_4d_removeVal.png[width=50%, link="{imagesdir}/Fig6_4d_removeVal.svg", window="_blank"]

[.text-center]
d). Function of deletion `RemoveVal(val)`

//image::{imagesdir}/Fig6_4d_removeVal.png[width=100%]
image::{imagesdir}/Fig6_4e_pushVal.png[width=50%, link="{imagesdir}/Fig6_4e_pushVal.svg", window="_blank"]

//image::{imagesdir}/Fig6_4e_nodeWithVal.png[width=75%]
image::{imagesdir}/Fig6_4e_nodeWithVal.png[width=50%, link="{imagesdir}/Fig6_4e_nodeWithVal.svg", window="_blank"]

[.text-center]
e). Function of inserting by value `PushVal + NodeWithVal`

//image::{imagesdir}/Fig6_4f_removeDupli.png[width=75%]
image::{imagesdir}/Fig6_4f_removeDupli.png[width=75%, link="{imagesdir}/Fig6_4f_RemoveDupli.svg", window="_blank"]

[.text-center]
f). Function of removing duplicates `removeDupli`

[.text-center]
Figure 6.4. DRAKON-diagram of algorithms deletion, search, insertion by value and dublicate deletion


=== 6.4. Hashing

==== Overview of Hash Tables

The time required to locate an item within a data set depends primarily on the number of value comparisons performed during the search process. In order to reduce search times and thus improve computational efficiency, fewer comparisons are needed. This can be achieved by converting a larger data set into a smaller range called hashing, resulting in hash tables.

From the perspective of the theory of abstract data types (ADT), a hash table is a data structure that implements the interface of an associative array that allows you to store key-value pairs and perform three basic operations: the operation of adding a new pair, search operation and operation to delete the key-value pair.

From a programming perspective, a hash table is a collection of key–value pairs, where each key is transformed by a special function called a hash function into an index that determines the storage location of the value. A hash table, in turn, consists of buckets, a set of elements with matching or close hash values of the function.

We will conduct a detailed analysis of the hash table creation process utilizing the JavaScript programming language within the DrakonTech. First, a hash table structure is created through the `createHashTable function` that initializes an array of specified size filled with null values (Figure 6.5a): 

image::{imagesdir}/Fig6_5a_createHashTable.png[width=50%]

[.text-center]
Figure 6.5a. DRAKON-diagram of Hash Table Creation

For storing individual elements, the `createNode function` is used (see Figure 6.5b), 
which creates a node containing the key-value pair and an optional reference to the next node for collision resolution through chaining ()

image::{imagesdir}/Fig6_5b_createNodes.png[width=50%]

[.text-center]
Figure 6.5b. DRAKON-diagram of Node Creation


These two fundamental functions provide the foundation for building a complete hash table implementation 
in JavaScript, enabling efficient key-value storage and retrieval operations.

As an example, consider constructing a hash table of size `m = 16` for a collection of 16 key-value pairs, where the key is an identification number and the value is a full name (Table 1). 

[.text-right]
.Table 1. The collection of 16 key-value pairs

[cols="1,1", options="header"]
|===
| Key | Value

| 123456
| John J. Doe

| 987654
| Jane K. Smith

| 112233
| Peter L. Jones

| 556677
| Mary V. Brown

| 334455
| David A. Davis

| 778899
| Susan G. Wilson

| 223344
| Michael D. Garcia

| 667788
| Linda E. Rodriguez

| 445566
| Christopher H. Martinez

| 889900
| Jessica F. Anders

| 135790
| Matthew B. Taylor

| 24689
| Ashley C. Thomas

| 975310
| Andrew I. Jackson

| 864201
| Sarah N. White

| 753192
| Daniel O. Harris

| 642083
| Brittany P. Lewis
|===

A **hash function** transforms a *key* (in our case, a six-digit numerical identifier) into a **hash address** — the index of a cell in the hash table where the corresponding value (for example, an employee record) will be stored.
The **value itself is not hashed**; it is simply stored at the computed address. Thus, hashing is always applied **to the key only**, providing fast and efficient access to data based on the key.

Each cell (or slot) in the hash table represents a collection of singly linked nodes, where each node contains three fields: the key, the value, and the address of the next node stored in the same slot.

Depending on how many elements are mapped to the same hash address, three situations may occur:
• Empty slot – no elements are mapped to this address.
• Single-node slot – exactly one key–value pair occupies this position.
• Chained slot – multiple nodes are linked together when several keys produce the same hash value (a collision).

There are many different types of hash functions, and they vary in design, performance, and collision behavior. However, to demonstrate the hashing process, we will choose the simplest hash function, calculated as the remainder of dividing the hash table element's `key` by the number of buckets (`size`), where a bucket represents a slot or container in the hash table that can hold one or more elements.

[source,js]
----
function hashFunc(key, size) {
    return Math.abs(key) % size;
}
----

In our case, we have chosen the number of buckets (`size`) to be 16. As a result of applying the hash function, a hash table with 16 buckets is formed. Figure 6.5.c shows slots containing information about (key, value) pairs:

[source,js]
----
Slot 0: [123456, "John J. Doe"]
Slot 0: 223344 -> Michael D. Garcia -> 123456 -> John J. Doe
Slot 1: 24689 -> Ashley C. Thomas
Slot 2: Empty
Slot 3: 642083 -> Brittany P. Lewis -> 778899 -> Susan G. Wilson
Slot 4: Empty
Slot 5: 556677 -> Mary V. Brown
Slot 6: 987654 -> Jane K. Smith
Slot 7: 334455 -> David A. Davis
Slot 8: 753192 -> Daniel O. Harris
Slot 9: 864201 -> Sarah N. White -> 112233 -> Peter L. Jones
Slot 10: Empty
Slot 11: Empty
Slot 12: 889900 -> Jessica F. Anders -> 667788 -> Linda E. Rodriguez
Slot 13: Empty
Slot 14: 975310 -> Andrew I. Jackson -> 135790 -> Matthew B. Taylor -> 445566 -> Christopher H. Martinez
Slot 15: Empty
----

**Collision Resolution: Separate Chaining with a Linked List**

A hash function will often map different keys to the same bucket; this is called a collision. As we can see in the example, Buckets 9, 12, and 14 each contain more than one element. To handle these collisions, our hash table uses a method called separate chaining.

In this method, each bucket is implemented as the head of a singly linked list. Instead of holding a single element, a bucket holds a pointer to the first node in a chain of elements that all hash to that same bucket index.

Each `Linked List Node` in the chain represents a block containing the `Element` and a `Pointer` to the next node. The structure of this node is fundamental to the implementation and consists of three fields:
Key: The unique identifier for the element.
Value: The actual data associated with the key.
Next: A pointer (or reference) to the next node in the linked list. If there is no next node (i.e., this is the last node in the chain), this field contains null. This node structure is visualized in Figure 6.5c.

image::{imagesdir}/Fig6_5c_bucket.png[width=100%]

[.text-center]
Figure 6.5c. Hash Table Bucket Implemented with a Linked List (Chaining) 

How It Works in Practice
Insertion: When a new (key, value) pair is inserted, the hash function `hashFunc(key, 16)` calculates the index of the target bucket. If the bucket is empty, a new node is created, filled with the key and value, its Next pointer is set to null, and the bucket is made to point to this new node. If the bucket is not empty (a collision occurs), a new node is created and is then linked into the existing list. A common and efficient method is to insert it at the beginning of the chain (LIFO method). In our example (Bucket 9), the last element inserted (864201) became the head of the chain, followed by the previously inserted element (112233).
This approach ensures constant-time average performance for insertion, lookup, and deletion operations, assuming a well-designed hash function and a reasonable load factor.


DRAKON-diagrams of algorithms for implementing the basic functions of working with hash tables are shown in Figure 6.6.

a). Hash Table Creation Function 
The algorithm encapsulates the entire logic described above: calculating the bucket index, handling an empty bucket, and resolving collisions by chaining a new node into the existing linked list.

//image::{imagesdir}/Fig6_5a_hashInserr.png[width=75%]
image::{imagesdir}/Fig6_6a_hashInsert.png[width=75%, link="{imagesdir}/Fig6_6a_hashInsert.svg", window="_blank"]

b). Hash Table Search Function

To find a value by its key, the hash function is applied to find the correct bucket. The linked list in that bucket is then traversed from the head, comparing the search key with the key field of each node until a match is found or the end of the list (null) is reached.

//image::{imagesdir}/Fig6_5b_searchHash.png[width=75%]
image::{imagesdir}/Fig6_6b_searchHash.png[width=75%, link="{imagesdir}/Fig6_6b_searchHash.svg", window="_blank"]

c). Hash Table Traversal Function 

This function demonstrates how to iterate through the entire hash table, printing all stored Elements and revealing the structure of the linked list chains used for collision resolution.
//image::{imagesdir}/Fig6_5c_hashTraverse.png[width=75%]
image::{imagesdir}/Fig6_6c_hashTraverse.png[width=50%, link="{imagesdir}/Fig6_6c_hashTraverse.svg", window="_blank"]

d) Hash Table Deletion Function

Consider the algorithm for removing an element from the hash table.Suppose we delete element 123456. First, the bucket containing the item to be removed is determined. It then passes through the elements of this bucket, after each check `node.value === value`, the current element is stored in the `nodePrev` variable. If the above condition is met, the `nodePrev.nextNode` field (`0xc0000386d0`) is changed to (`0xc00384f0`), that is, the deleted element is skipped:

//image::{imagesdir}/Fig6_5d_hashRemove.png[width=75%]
image::{imagesdir}/Fig6_6d_hashRemove.png[width=75%, link="{imagesdir}/Fig6_6d_hashRemove.svg", window="_blank"]

[.text-center]
Figure 6.6. Basic DRAKON-diagrams of Hash Table Algorithms

==== Choosing a Hash Function

The efficiency of a hash table largely depends on the quality of its *hash function*.
A well-designed function should distribute keys as evenly as possible across all available buckets, minimizing the likelihood of collisions.

In this section, we used a simple modular hash function:

[source,js]
----
function hashFunc(key, size) {
    return Math.abs(key) % size;
}
----

This approach is sufficient for demonstration purposes and for relatively small data sets where keys are uniformly distributed.
However, as the data volume grows, the limitations of such a simple function become more noticeable.
For large-scale systems, more advanced hash functions — based on **bitwise transformations**, **multiplicative methods**, or even **cryptographic algorithms** — provide a more uniform distribution of keys and reduce clustering.

The advantages of complex hash functions become evident when:

* The number of stored records reaches thousands or millions.
* The key values show regular or repetitive patterns (for example, sequential identifiers).
* Collisions significantly affect performance due to frequent insertions and deletions.

Ultimately, choosing a hash function involves balancing **speed** and **uniformity** of key distribution.
In practical systems, the best results are often achieved by empirical testing on real data samples rather than through purely theoretical analysis.


