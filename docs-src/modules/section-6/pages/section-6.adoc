:imagesdir: ../assets/images

[.text-justify]
:Figure-caption!:

== SECTION 6. BASIC SEARCH ALGORITHMS

Searching is one of the most important algorithms for processing data
structures. Search algorithms are designed to check the presence of an
element or extract an element from any data structure in which it is
stored. More strictly, the search problem can be formulated as follows:
find one or more elements in the set, and the elements sought must have
a certain property. This property can be absolute or relative. A
relative property characterizes an element with respect to other
elements: for example, a minimum element in a set of numbers.

There are a lot of search algorithms. Their complexity varies from
simple sequential search algorithms, in extremely efficient but limited
binary search algorithms. Of particular note are algorithms based on the
presentation of a core set of data in a different, more searchable form,
which are used in real-world applications for processing data sets in
huge databases.

There is no single algorithm to solve the search problems. Some of the algorithms run faster than others, but require
additional RAM to run. Others run very quickly, but can only be used for
pre-sorted arrays. At the same time, the analysis of search algorithms
is somewhat different from sorting algorithms. In particular, there is
no sustainability problem for them. In this case there may be situations
that require introduction of new criteria of complexity and its
assessment. In general, all algorithms are reduced to
following steps :

[arabic]
. establishing the property of the elements of the source set; in most
cases, these are the values of the elements;
. match the value of the element with the reference property (for
absolute properties) or compare the properties of the two elements (for
relative properties);
. traversing the elements of the set.

In principle, search algorithms differ between search methods and search
strategies. Based on the type of search operation, these algorithms are
usually classified in two categories:

_Sequential Search:_ The list or array is performed sequentially and
each element is checked.

_Interval search:_ These algorithms are specifically designed to search
in sorted data structures. These types of search algorithms are much
more efficient than linear search because they repeatedly target the
center of the search structure and divide the search space in half.

This section examines the primary algorithms used for searching data structures. 
To enhance the understanding of the practical applications of these algorithms, 
DRAKON-diagrams are provided along with assessments of their time and space complexity.

== List of Figures

|===
| Figure | Title | Description

| 6.1 | Linear Search | DRAKON-diagram of the Linear Search Algorithm
| 6.2 | Sorted Data Search | DRAKON-diagram of the Search in a Sorted Array
| 6.3 | Binary Search | DRAKON-diagram of the Binary Search Algorithm
| 6.4a | Main Function | Entry Point for Linked List Operations
| 6.4b | PushFront / PushBack | Adding New Items to the List
| 6.4c | SearchData | Searching for an Element in a Linked List
| 6.4d | RemoveVal | Deleting a Node by Value
| 6.4e | PushVal / NodeWithVal | Inserting by Value and Locating Node by Value
| 6.4f | RemoveDupli | Removing Duplicate Nodes
| 6.a | Hash Table Creation | Creating a Hash Table Structure
| 6.b | Hash Table Search | Searching for an Element by Key
| 6.c | Hash Table Traversal | Traversing Hash Table Items
| 6.d | Hash Table Deletion | Deleting an Element by Key
|=== 

[NOTE]
====
All illustrations in this section are provided in the **SVG** format.  
Click on any image to open it in a separate window for detailed viewing.
====

=== 6.1. Linear data searching

a). Linear searching of input data

In the case of a linear search of an element in an unordered dataset,
for example, in an array or in a slice, the simplest algorithm is to
view all elements until the desired value is found (Figure 6.1).

//image::{imagesdir}/Fig6_1_searchElement_v2.png[width=75%]

image::{imagesdir}/Fig6_1_searchElement.png[width=50%, link="{imagesdir}/Fig6_1_searchElement.svg", window="_blank"]

[.text-center]
Figure 6.1. DRAKON-diagram of the Linear Search Algorithm
              
This algorithm is not very effective, but it works on arbitrary
collections. _Time complexity:_ O(n). In the worst case (the desired
element is in the last position) to find the element you need to pass
all the elements cut. Here "n" is the size of the cut. additional
memory. In principle, another worst case is the absence of the necessary
element. _Space complexity:_ O(1). No additional memory is required to
accommodate the slice.

b). Linear search of sorted data in slice

If the elements of the dataset are sorted by ascending or descending,
finding the desired element is much more efficient than in an unordered
linear search. Because in many cases, you don’t have to go through the
whole list. For example, when an item with a higher value is discovered
as a result of passing through an increasing sorted list, the search is
stopped. This approach saves time and increases productivity. Figure
6.2. shows the DRAKON-diagram of this algorithm.

//image::{imagesdir}/Fig6_2_dataSorted.png[width=75%]
image::{imagesdir}/Fig6_2_dataSorted.png[width=50%, link="{imagesdir}/Fig6_2_dataSorted.svg", window="_blank"]


[.text-center]
Figure 6.2. DRAKON-diagram of the Search in a Sorted Array


=== 6.2. Binary search for data in a sorted data

Binary search is performed as follows:

[arabic]
. Specifies the value of the element in the middle of the data
structure. The resulting value is compared to the value you are looking
for.
. If the search value is less than the value of the means, the search is
carried out in the first half of the elements, otherwise - in the
second.3. The search is simply that the value of the middle element in
the selected half is again determined and compared to the key.
. The process continues until an item with the search value is found or
the search interval is empty.

The DRAKON-diagram of the binary search algorithm is represented in
Figure 6.3. (main() module is similar to the previous algorithm):

//image::{imagesdir}/Fig6_3_searchValue.png[width=75%]
image::{imagesdir}/Fig6_3_searchValue.png[width=50%, link="{imagesdir}/Fig6_3_searchValue.svg", window="_blank"]

[.text-center]
Figure 6.3. DRAKON-diagram of Binary Search algorithm

_Time complexity_ of binary search algorithm belongs to class O(log n).
The way to interpret this is that the asymptotic increase in the time
taken by a function to perform a given input set of size n will not
exceed log n. _Space complexity_: O(1). That is, no extra space
required.

=== 6.3. Searching in Single-Linked List

There are three possibilities for a single-linked list. First, the
desired value is missing from the list, second, the desired value is
encountered once and, third, the desired value is encountered
repeatedly. You can also set the task of removing duplicates, i.e.,
nodes that are redundant. To solve these problems it is necessary to
create a Single-Linked List, the items of which contain values "Smith
A.", "Shafler B.”, "Wiley D.", "Brown G.", "Black H.". In this list you
should delete the entry " Brown G." and then add a new entry "Singer B."
placing it after the entry "Wiley D.". After that, you should delete the
duplicates of the entry " Shafler B." leaving only one. The
corresponding DRAKON-diagrams are presented in Figure 6.4 a,b,c,d:

//image::{imagesdir}/Fig6_4a_main.png[width=75%]
image::{imagesdir}/Fig6_4a_main.png[width=50%, link="{imagesdir}/Fig6_4a_main.svg", window="_blank"]

[.text-center]
a). Function `main()``

b). function of pushing new items (`pushFront(list,val) and pushback(list,val)`)

//image::{imagesdir}/Fig6_4b_pushFront.png[width=75%]
image::{imagesdir}/Fig6_4b_pushFront.png[width=50%, link="{imagesdir}/Fig6_4b_pushFront.svg", window="_blank"]

//image::{imagesdir}/Fig6_4b_pushBack.png[width=75%]
image::{imagesdir}/Fig6_4b_pushBack.png[width=50%, link="{imagesdir}/Fig6_4b_pushBack.svg", window="_blank"]

[.text-center]

Figure 6.4. DRAKON-diagrams of  pushFront/pushBack algorithms

c). function of searching `searchData(val)`

//image::{imagesdir}/Fig6_4c_searchData.png[width=75%]
image::{imagesdir}/Fig6_4c_searchData.png[width=50%, link="{imagesdir}/Fig6_4c_searchData.svg", window="_blank"]

[.text-center]

Figure 6.4. DRAKON-diagrams of  search algorithms

d). function of deletion _RemoveVal(val)_

//image::{imagesdir}/Fig6_4d_removeVal.png[width=75%]
image::{imagesdir}/Fig6_4d_removeVal.png[width=50%, link="{imagesdir}/Fig6_4d_removeVal.svg", window="_blank"]

[.text-center]
Figure 6.4. DRAKON-diagrams of  deletion algorithms

e). function of inserting by value _PushVal + NodeWithVal_

//image::{imagesdir}/Fig6_4d_removeVal.png[width=100%]
image::{imagesdir}/Fig6_4e_pushVal.png[width=50%, link="{imagesdir}/Fig6_4e_pushVal.svg", window="_blank"]

//image::{imagesdir}/Fig6_4e_nodeWithVal.png[width=75%]
image::{imagesdir}/Fig6_4e_nodeWithVal.png[width=50%, link="{imagesdir}/Fig6_4e_nodeWithVal.svg", window="_blank"]

f). function of removing duplicates _removeDupli_

//image::{imagesdir}/Fig6_4f_removeDupli.png[width=75%]
image::{imagesdir}/Fig6_4f_removeDupli.png[width=75%, link="{imagesdir}/Fig6_4f_RemoveDupli.svg", window="_blank"]

[.text-center]
Figure 6.4. DRAKON-diagram of algorithms deletion, search, insertion by value and dublicate deletion


=== 6.4. Hashing

==== Over View of Hash Tables

The search time of an item in a data set depends on the number of element value comparisons. In order to reduce search times and thus improve computational efficiency, fewer comparisons are needed. This can be achieved by converting a larger data set into a smaller range called hashing, resulting in hash tables.

From the perspective of the theory of abstract data types (ADT), a hash-table is a data structure that implements the interface of an associative array that allows you to store key-value pairs and perform three basic operations: the operation of adding a new pair, search operation and operation to delete the key-value pair.

From a programming position, a hash table is a collection of items containing a key-value pair, where the key is computed by a special function called a hash function. A hash-table, in turn, consists of buckets, a set of elements with matching or close hash values of the function.

We will conduct a detailed analysis of the hash table creation process utilizing the JavaScript programming language within the DrakonTech. First, a hash table structure is created through the `createHashTable function` that initializes an array of specified size filled with null values (Figure 6.5a): 

image::{imagesdir}/Fig6_5a_createHashTable.png[width=50%]

[.text-center]
Figure 6.5a. DRAKON-diagram of Hash Table Creation

For storing individual elements, the `createNode function` is used (see Figure 6.5b), 
which creates a node containing the key-value pair and an optional reference to the next node for collision resolution through chaining ()

image::{imagesdir}/Fig6_5b_createNodes.png[width=50%]

[.text-center]
Figure 6.5b. DRAKON-diagram of Node Creation


These two fundamental functions provide the foundation for building a complete hash table implementation 
in JavaScript, enabling efficient key-value storage and retrieval operations.

As an example, consider constructing a hash-table of size `m = 32` for a collection of 16 key-value pairs, where the key is an identification number and the value is a full name (Table 1). 

[.text-right]
Table 1. The collection of 16 key-value pairs

[cols="1,2,1,3,2", options="header"]
|===
| Slot |Address of memory| Key | Value |Next Address 

| 0
| 0x0000
| Empty
| Empty
| Empty

| 1
| 0x1000
| 642083
| Brittany P. Lewis
| null

| 2
| 0x2000
| 753192
| Daniel O. Harris
| null

| 3
| 0x3000
| Empty
| Empty
| Empty

| 4
| 0x4000
| 556677
| Mary V. Brown
| null

| 5
| 0x5000
| Empty
| Empty
| Empty

| 6
| 0x6000
| Empty
| Empty
| Empty

| 7
| 0x7000
| Empty
| Empty
| Empty

| 8
| 0x8000
| 889900
| Jessica F. Anderson
| 0x8100

|
| 0x8100
| 112233
| Peter L. Jones
| null

| 9
| 0x9000
| Empty
| Empty
| Empty

| 10
| 0xA000
| 334455
| David A. Davis
| null

| 11
| 0xB000
| Empty
| Empty
| *Empty`

| 12
| 0xC000
| 24689
| Ashley C. Thomas
| null

| 13
| 0xD000
| Empty
| Empty
| *Empty`

| 14
| 0xE000
| 778899
| Susan G. Wilson
| 0xE100

|
| 0xE100
| 987654
| Jane K. Smith
| null

| 15
| 0xF000
| 123456
| John J. Doe
| null

| 16
| 0x10000
| Empty
| Empty
| Empty

| 17
| 0x11000
| Empty
| Empty
| *Empty`

| 18
| 0x12000
| Empty
| Empty
| *Empty`

| 19
| 0x13000
| Empty
| Empty
| *Empty`

| 20
| 0x14000
| Empty
| Empty
| *Empty`

| 21
| 0x15000
| Empty
| Empty
| *Empty`

| 22
| 0x16000
| Empty
| Empty
| *Empty`

| 23
| 0x17000
| 135790
| Matthew B. Taylor
| null

| 24
| 0x18000
| 445566
| Christopher H. Martinez
| null

| 25
| 0x19000
| 864201
| Sarah N. White
| null

| 26
| 0x1A000
| Empty
| Empty
| *Empty`

| 27
| 0x1B000
| Empty
| Empty
| *Empty`

| 28
| 0x1C000
| 223344
| Michael D. Garcia
| null

| 29
| 0x1D000
| Empty
| Empty
| *Empty`

| 30
| 0x1E000
| 667788
| Linda E. Rodriguez
| null

| 31
| 0x1F000
| 975310
| Andrew I. Jackson
| null
|===

A **hash function** transforms a *key* (in our case, a six-digit numerical identifier) into a **hash address** — the index of a cell in the hash table where the corresponding value (for example, an employee record) will be stored.
The **value itself is not hashed**; it is simply stored at the computed address. Thus, hashing is always applied **to the key only**, providing fast and efficient access to data based on the key.

Each cell (or slot) in the hash table represents a collection of singly linked nodes, where each node contains three fields: the key, the value, and the address of the next node stored in the same slot.


Depending on how many elements are mapped to the same hash address, three situations may occur:

Empty slot – no elements have been hashed to this address.
Single-node slot – only one key-value pair occupies this position.
Chained slot – multiple nodes form a linked list when several keys produce the same hash value (a collision).

There are many different types of hash functions, and they vary in design, performance, and collision behavior. However, to demonstrate the hashing process, we will choose the simplest hash function, calculated as the remainder of dividing the hash table element's `key` by the number of buckets (`size`), where a bucket represents a slot or container in the hash table that can hold one or more elements.

[source,js]
----
function hashFunc(key, size) {
    return Math.abs(key) % size;
}
----

In our case, we have chosen the number of buckets (`size`) to be 16. As a result of applying the hash function, a hash table with 16 buckets is formed. Figure 6.5.c shows slots containing information about (key, value) pairs:

[source,js]
----
Slot 0: [123456, "John J. Doe"]
Slot 1: []
Slot 2: []
Slot 3: [642083, "Brittany P. Lewis"]
Slot 4: []
Slot 5: [556677, "Mary V. Brown"]
Slot 6: [987654, "Jane K. Smith"]
Slot 7: [334455, "David A. Davis"]
Slot 8: [753192, "Daniel O. Harris"]
Slot 9: [112233, "Peter L. Jones"] -> [24689, "Ashley C. Thomas"] -> [864201, "Sarah N. White"]
Slot 10: [223514, "Michael D. Garcia"]
Slot 11: []
Slot 12: [667788, "Linda E. Rodriguez"] -> [889900, "Jessica F. Anders"]
Slot 13: []
Slot 14: [445566, "Christopher H. Martinez"] -> [135790, "Matthew B. Taylor"] -> [975310, "Andrew I. Jackson"]
Slot 15: [778399, "Susan G. Wilson"]
----

Collision Resolution: Separate Chaining with a Linked List
A hash function will often map different keys to the same bucket; this is called a collision. As we can see in the example, Buckets 9, 12, and 14 each contain more than one element. To handle these collisions, our hash table uses a method called separate chaining.

In this method, each bucket is implemented as the head of a singly linked list. Instead of holding a single element, a bucket holds a pointer to the first node in a chain of elements that all hash to that same bucket index.

Bucket Structure: The Linked List Node
Each element in the chain is stored within a node. The structure of this node is fundamental to the implementation and consists of three fields:

Key: The unique identifier for the element.

Value: The actual data associated with the key.

Next: A pointer (or reference) to the next node in the linked list. If there is no next node (i.e., this is the last node in the chain), this field contains null.

This node structure is visualized in Figure 6.5c.

image::{imagesdir}/Fig6_5c_bucket.png[width=50%]

[.text-center]
Figure 6.5c. Hash Table Bucket Implemented with a Linked List (Chaining) 

How It Works in Practice
Insertion: When a new (key, value) pair is inserted, the hash function hashFunc(key, 16) calculates the index of the target bucket.

If the bucket is empty, a new node is created, filled with the key and value, its Next pointer is set to null, and the bucket is made to point to this new node.

If the bucket is not empty (a collision occurs), a new node is created and is then linked into the existing list. A common and efficient method is to insert it at the beginning of the chain. In our example (Bucket 9), the chain was built sequentially: first 112233, then 24689 was added to the end, and finally 864201 was added to the end. 

Fig. 6.5 shows a DRAKON-diagram of the `hashInsert(hash, key, value)` function, which constructs the hash table by creating and inserting a new node for each key-value pair. The algorithm encapsulates the entire logic described above: calculating the bucket index, handling an empty bucket, and resolving collisions by chaining a new node into the existing linked list.

image::{imagesdir}/Fig6_5d_hashInsert.png[width=50%, link="{imagesdir}/Gig6_5d_hashInsert.svg", window = "_blank"]  

[.text-center]
Fig. 6.5: DRAKON-diagram of the hashInsert(hash, key, value) function

Lookup: To find a value by its key, the hash function is applied to find the correct bucket. The linked list in that bucket is then traversed from the head, comparing the search key with the key field of each node until a match is found or the end of the list (null) is reached.

Deletion: To delete an element, the hash function leads us to the correct bucket, we traverse the linked list to find the node, and then we remove it by adjusting the Next pointer of the previous node.

This chaining method allows the hash table to store an arbitrary number of elements regardless of its fixed size (16 buckets), while maintaining efficient average-case performance for insertions, lookups, and deletions.






The implementation of the basic hash table functions using the hash
function is as follows: 
1.Create a `HashTable` structure list of the
size `m` to store objects. 
2. Compute the object’s hash code by passing it
through the hashfunction. 
3. Get the bucket hash indices where the
objects will be saved. 
4. Save these objects in the designated bucket.

DRAKON-diagrams of algorithms for implementing the main functions of
working with hash-tables are shown in Figure 6.5.

a). Hash Table Creation Function 

//image::{imagesdir}/Fig6_5a_hashInserr.png[width=75%]
image::{imagesdir}/Fig6_5a_hashInsert.png[width=50%, link="{imagesdir}/Fig6_5a_hashInsert.svg", window="_blank"]

b). Hash Table Search Function

//image::{imagesdir}/Fig6_5b_searchHash.png[width=75%]
image::{imagesdir}/Fig6_5b_searchHash.png[width=50%, link="{imagesdir}/Fig6_5b_searchHash.svg", window="_blank"]

c). Hash Table Traversal Function 

//image::{imagesdir}/Fig6_5c_hashTraverse.png[width=75%]
image::{imagesdir}/Fig6_5c_hashTraverse.png[width=50%, link="{imagesdir}/Fig6_5c_hashTraverse.svg", window="_blank"]

d) Hash Table Deletion Function

Consider the algorithm for removing an element from the hash-table.
Suppose we delete element 74. First, the bucket containing the item to
be removed is determined. It then passes through the elements of this
bucket, where after each `node.Value == value` check, the current
element is stored in the `nodePrev` variable. If the above condition is
met, the `nodePrev.nextNode` field (`0xc0000386d0`) is changed to
(`0xc00384f0`), that is, the deleted element is skipped (Figure 6.5d.):

//image::{imagesdir}/Fig6_5d_hashRemove.png[width=75%]
image::{imagesdir}/Fig6_5d_hashRemove.png[width=75%, link="{imagesdir}/Fig6_5d_hashRemove.svg", window="_blank"]

[.text-center]
Figure 6.5. DRAKON-diagrams of Hash Table Algorithms


Another example of a "good" hash function is for use with integer key
values, the mean square method. The mean square method squares the key
value and then extracts the average digits of the result, giving a value
in the range from 0 to M. Software implementation of hash function
algorithm creation in Golang language is reduced to the use of built-in
functions of conversion of integers into string (`strconv.Atoi(i)`) and
vice versa (`strc__onv.Itoa(i))`).__ For example, for any four-digit
number, the hash function is:



A more realistic scenario in hash table construction involves the phenomenon
known as collision, where multiple keys hash to the same bucket or index. 
In many cases, two or more keys are hashed identically, resulting in their 
mapping to the same slot in the hash table. To handle this situation, there are 
two primary strategies: either locate an alternative entry for the new key or 
maintain a separate list at each index in the hash table to accommodate all keys 
that hash to that index. These approaches represent two classic hashing schemes:


* оpen addressing hashing with linear testing;
* сhain hashing or so-called multidimensional hashing.

However, this topic is outside the scope of this manual.
