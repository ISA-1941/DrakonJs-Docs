:imagesdir: ../assets/images

[.text-justify]
:figure-caption!:

== SECTION 6. BASIC SEARCH ALGORITHMS

Searching is one of the most important algorithms for processing data
structures. Search algorithms are designed to check the presence of an
element or extract an element from any data structure in which it is
stored. More strictly, the search problem can be formulated as follows:
find one or more elements in the set, and the elements sought must have
a certain property. This property can be absolute or relative. A
relative property characterizes an element with respect to other
elements: for example, a minimum element in a set of numbers.

There are a lot of search algorithms. Their complexity varies from
simple sequential search algorithms, in extremely efficient but limited
binary search algorithms. Of particular note are algorithms based on the
presentation of a core set of data in a different, more searchable form,
which are used in real-world applications for processing data sets in
huge databases.

There is no single algorithm to solve the search problems. Some of the algorithms run faster than others, but require
additional RAM to run. Others run very quickly, but can only be used for
pre-sorted arrays. At the same time, the analysis of search algorithms
is somewhat different from sorting algorithms. In particular, there is
no sustainability problem for them. In this case there may be situations
that require introduction of new criteria of complexity and its
assessment. In general, all algorithms are reduced to
following steps :

[arabic]
. establishing the property of the elements of the source set; in most
cases, these are the values of the elements;
. match the value of the element with the reference property (for
absolute properties) or compare the properties of the two elements (for
relative properties);
. traversing the elements of the set.

In principle, search algorithms differ between search methods and search
strategies. Based on the type of search operation, these algorithms are
usually classified in two categories:

_Sequential Search:_ The list or array is performed sequentially and
each element is checked.

_Interval search:_ These algorithms are specifically designed to search
in sorted data structures. These types of search algorithms are much
more efficient than linear search because they repeatedly target the
center of the search structure and divide the search space in half.

This section examines the primary algorithms used for searching data structures. 
To enhance the understanding of the practical applications of these algorithms, 
DRAKON-diagrams are provided along with assessments of their time and space complexity.

=== 6.1. Linear data searching

a). Linear searching of input data

In the case of a linear search of an element in an unordered dataset,
for example, in an array or in a slice, the simplest algorithm is to
view all elements until the desired value is found (Figure 6.1).

//image::{imagesdir}/Fig6_1_searchElement_v2.png[width=75%]

image::{imagesdir}/Fig6_1_searchElement.png[width=75%, link="{imagesdir}/Fig6_1_searchElement.svg", window="_blank"]

[.text-center]
Figure 6.1. DRAKON-diagrams of linear search algorithm

This algorithm is not very effective, but it works on arbitrary
collections. _Time complexity:_ O(n). In the worst case (the desired
element is in the last position) to find the element you need to pass
all the elements cut. Here "n" is the size of the cut. additional
memory. In principle, another worst case is the absence of the necessary
element. _Space complexity:_ O(1). No additional memory is required to
accommodate the slice.

b). Linear search of sorted data in slice

If the elements of the dataset are sorted by ascending or descending,
finding the desired element is much more efficient than in an unordered
linear search. Because in many cases, you don’t have to go through the
whole list. For example, when an item with a higher value is discovered
as a result of passing through an increasing sorted list, the search is
stopped. This approach saves time and increases productivity. Figure
6.2. shows the DRAKON-diagram of this algorithm.

//image::{imagesdir}/Fig6_2_dataSorted.png[width=75%]
image::{imagesdir}/Fig6_2_dataSorted.png[width=75%, link="{imagesdir}/Fig6_2_dataSorted.svg", window="_blank"]


[.text-center]
Figure 6.2. DRAKON-diagram of searching sorted data algorithm

=== 6.2. Binary search for data in a sorted data

Binary search is performed as follows:

[arabic]
. Specifies the value of the element in the middle of the data
structure. The resulting value is compared to the value you are looking
for.
. If the search value is less than the value of the means, the search is
carried out in the first half of the elements, otherwise - in the
second.3. The search is simply that the value of the middle element in
the selected half is again determined and compared to the key.
. The process continues until an item with the search value is found or
the search interval is empty.

The DRAKON-diagram of the binary search algorithm is represented in
Figure 6.3. (main() module is similar to the previous algorithm):

//image::{imagesdir}/Fig6_3_searchValue.png[width=75%]
image::{imagesdir}/Fig6_3_searchValue.png[width=75%, link="{imagesdir}/Fig6_3_searchValue.svg", window="_blank"]

[.text-center]
Figure 6.3. DRAKON-diagram of Binary Search algorithm

_Time complexity_ of binary search algorithm belongs to class O(log n).
The way to interpret this is that the asymptotic increase in the time
taken by a function to perform a given input set of size n will not
exceed log n. _Space complexity_: O(1). That is, no extra space
required.

=== 6.3. Searching in Single-Linked List

There are three possibilities for a single-linked list. First, the
desired value is missing from the list, second, the desired value is
encountered once and, third, the desired value is encountered
repeatedly. You can also set the task of removing duplicates, i.e.,
nodes that are redundant. To solve these problems it is necessary to
create a Single-Linked List, the items of which contain values "Smith
A.", "Shafler B.”, "Wiley D.", "Brown G.", "Black H.". In this list you
should delete the entry " Brown G." and then add a new entry "Singer B."
placing it after the entry "Wiley D.". After that, you should delete the
duplicates of the entry " Shafler B." leaving only one. The
corresponding DRAKON-diagrams are presented in Figure 6.4 a,b,c,d:

//image::{imagesdir}/Fig6_4a_main.png[width=75%]
image::{imagesdir}/Fig6_4a_main.png[width=75%, link="{imagesdir}/Fig6_4a_main.svg", window="_blank"]

[.text-center]
a). Function `main()``

b). function of pushing new items (`pushFront(list,val) and pushback(list,val)`)

//image::{imagesdir}/Fig6_4b_pushFront.png[width=75%]
image::{imagesdir}/Fig6_4b_pushFront.png[width=40%, link="{imagesdir}/Fig6_4b_pushFront.svg", window="_blank"]

//image::{imagesdir}/Fig6_4b_pushBack.png[width=75%]
image::{imagesdir}/Fig6_4b_pushBack.png[width=40%, link="{imagesdir}/Fig6_4b_pushBack.svg", window="_blank"]

[.text-center]

Figure 6.4. DRAKON-diagrams of  pushFront/pushBack algorithms

c). function of searching `searchData(val)`

//image::{imagesdir}/Fig6_4c_searchData.png[width=75%]
image::{imagesdir}/Fig6_4c_searchData.png[width=75%, link="{imagesdir}/Fig6_4c_searchData.svg", window="_blank"]

[.text-center]

Figure 6.4. DRAKON-diagrams of  search algorithms

d). function of deletion _RemoveVal(val)_

//image::{imagesdir}/Fig6_4d_removeVal.png[width=75%]
image::{imagesdir}/Fig6_4d_removeVal.png[width=75%, link="{imagesdir}/Fig6_4d_removeVal.svg", window="_blank"]

[.text-center]
Figure 6.4. DRAKON-diagrams of  deletion algorithms

e). function of inserting by value _PushVal + NodeWithVal_

//image::{imagesdir}/Fig6_4d_removeVal.png[width=100%]
image::{imagesdir}/Fig6_4e_pushVal.png[width=75%, link="{imagesdir}/Fig6_4e_pushVal.svg", window="_blank"]

//image::{imagesdir}/Fig6_4e_nodeWithVal.png[width=75%]
image::{imagesdir}/Fig6_4e_nodeWithVal.png[width=75%, link="{imagesdir}/Fig6_4e_nodeWithVal.svg", window="_blank"]

[.text-center]
f). function of removing duplicates _removeDupli_

//image::{imagesdir}/Fig6_4f_removeDupli.png[width=75%]
image::{imagesdir}/Fig6_4f_removeDupli.png[width=75%, link="{imagesdir}/Fig6_4f_RemoveDupli.svg", window="_blank"]

[.text-center]
Figure 6.4. DRAKON-diagram of algorithms deletion, search, insertion by value and dublicate deletion

=== 6.4. Hashing

The search time of an item in a data set depends on the number of
element value comparisons. In order to reduce search times and thus
improve computational efficiency, fewer comparisons are needed. This can be achieved by converting a larger data set into a smaller range called hashing, resulting in hash tables.

From the perspective of the theory of abstract data types (ADT), a
hash-table is a data structure that implements the interface of an
associative array that allows you to store key-value pairs and perform three basic operations: the operation of adding a new pair, search
operation and operation to delete the key-value pair. 
From a programming position, a hash table is a collection of items 
containing a key-value pair, where the key is computed by a special 
function called a `hash function`. A `hash-table`, in turn, 
consists of buckets, a set of elements with matching or close hash values
of the function. 
There are different methods of constructing a `hash function`, the simplest 
of which is the residual method, where the hash function is defined 
as the remainder of the division of two numbers (`x, m`), where `x` 
is the item of the set, `m` is the number of buckets. In JavaScript, 
the `hash function` for this method is: `h = x % m`.

We will conduct a detailed analysis of the hash table creation process 
utilizing the JavaScript programming language within the DrakonTech.   
First, a variable of the `Node` type is created, defined as a structure 
consisting of two fields: the element value is `Value int` and the next 
element address is `Next *Node`. In fact, it is a single linked list (see Section 1).

type Node struct \{ Value int Next *Node }

Then, a hash-table is created through a structure that has two fields:
the first field (`Table`) is a map that relates the integer (`hash
index`) to the associated list (`Node`), and the second - `Size`of
type `int`:

[source,go]
----
type HashTable struct {
Table map[int] *Node
Size int
}
----

As a result, this hash table would have to have as many single linked
lists (buckets) as was specified by the Size constant. In the above case
the number of slots is 15. 
As an example, consider constructing a hash-table of size `m` = 15 for a
collection of integers from 0 to 120. The hash table slots are
originally empty:

[cols="1,1,1,1,1,1,1,1,1,1,1,1,1,1,1", options="header"]
|===
|0 |1 |2 |3 |4 |5 |6 |7 |8 |9 |10 |11 |12 |13 |14

|- |- |- |- |- |- |- |- |- |- |- |- |- |- |-
|===

A hash function that establishes a relationship between an element and its 
corresponding slot must accept any element from the dataset, specifically 
ranging from 0 to 120, and return an integer that corresponds to a slot 
number between 0 and 14. The algorithm implementing the remainder method 
sequentially processes each element from the original set, dividing it by 15 
and returning the remainder as the hash value. This can be expressed as 
`\( h(item) = item \mod 15 \)`. For instance, the hash code for the element 119 
is calculated as `\( 119 \mod 15 = 14 \)` (where `\( 119 - 15 \times 7 = 14 \))`, 
thus placing the value 119 into the corresponding slot.

[cols="1,1,1,1,1,1,1,1,1,1,1,1,1,1,1", options="header"]
|===
|0 |1 |2 |3 |4 |5 |6 |7 |8 |9 |10 |11 |12 |13 |14

|- |- |- |- |- |- |- |- |- |- |- |- |- |- |119
|===

The algorithm then identifies slots for other elements, gradually
filling them. When the algorithm encounters element 104 in the loop,
then the remainder of the division is `104%15 = 14`, so this element will
also be included in the 14th slot. In this way, each slot will
accumulate corresponding elements with one index hash. For example, for
an index hash of 8, the slot will consist of these elements: 113 : 98 :
83 : 68 : 53 : 38 : 23 : 8. And the entire hash table will be as follows
(Table 6.1.):

Table 6.1. Hash-table of 15 slots

[options="header"]
|====
| 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 | 13 | 14
| 105 | 106 | 107 | 108 | 109 | 110 | 111 | 112 | 113 | 114 | 115 | 116 | 117 | 118 | 119
| 103 | 91 | 92 | 103 | 94 | 95 | 96 | 97 | 98 | 99 | 100 | 101 | 102 | 103 | 104
| 88 | 76 | 77 | 78 | 79 | 80 | 81 | 82 | 83 | 84 | 85 | 86 | 87 | 88 | 89
| 73 | 61 | 62 | 63 | 64 | 65 | 66 | 67 | 68 | 69 | 70 | 71 | 72 | 73 | 74
| 58 | 46 | 47 | 48 | 49 | 50 | 51 | 52 | 53 | 54 | 55 | 56 | 57 | 58 | 59
| 43 | 31 | 32 | 33 | 34 | 35 | 36 | 37 | 38 | 39 | 40 | 41 | 42 | 43 | 44
| 28 | 16 | 17 | 18 | 19 | 20 | 21 | 22 | 23 | 24 | 25 | 26 | 27 | 28 | 29
| 13 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 | 13 | 14
|====

Thus, the remainder method converts a collection of 120 integers into a
hash table of 15 slots. The search for an element is now greatly
accelerated as it takes two steps: first, the hash function `h =(x % m)`
computes the hash index, and then the search is done in a 7-element
slot. The algorithm based on the residual method is represented by the
following DRAKON-diagrams (Figure 6.6.). Here `hinsert` - module of
filling with elements of slots on `hash`-function, `hLookup`-module of
search of element in hash-table, `hTravers` - module of passage on
`hash`-table.

The implementation of the main hash table functions using the hash
function is as follows: 
1.Create a `HashTable` structure list of the
size `m` to store objects. 
2. Compute the object’s hash code by passing it
through the hashfunction. 
3. Get the bucket hash indices where the
objects will be saved. 
4. Save these objects in the designated bucket.

DRAKON-diagrams of algorithms for implementing the main functions of
working with hash-tables are shown in Figure 6.6.

a). Hash Table Creation Function 

//image::{imagesdir}/Fig6_5a_hashInserr.png[width=75%]
image::{imagesdir}/Fig6_5a_hashInsert.png[width=75%, link="{imagesdir}/Fig6_5a_hashInsert.svg", window="_blank"]

b). Hash Table Search Function

//image::{imagesdir}/Fig6_5b_searchHash.png[width=75%]
image::{imagesdir}/Fig6_5b_searchHash.png[width=75%, link="{imagesdir}/Fig6_5b_searchHash.svg", window="_blank"]

c). Hash Table Traversal Function 

//image::{imagesdir}/Fig6_5c_hashTraverse.png[width=75%]
image::{imagesdir}/Fig6_5c_hashTraverse.png[width=75%, link="{imagesdir}/Fig6_5c_hashTraverse.svg", window="_blank"]

d) Hash Table Deletion Function

Consider the algorithm for removing an element from the hash-table.
Suppose we delete element 74. First, the bucket containing the item to
be removed is determined. It then passes through the elements of this
bucket, where after each `node.Value == value` check, the current
element is stored in the `nodePrev` variable. If the above condition is
met, the `nodePrev.nextNode` field (`0xc0000386d0`) is changed to
(`0xc00384f0`), that is, the deleted element is skipped (Figure 6.5d.):

//image::{imagesdir}/Fig6_5d_hashRemove.png[width=75%]
image::{imagesdir}/Fig6_5d_hashRemove.png[width=75%, link="{imagesdir}/Fig6_5d_hashRemove.svg", window="_blank"]

[.text-center]
Figure 6.5. DRAKON-diagrams of hash-table algorithms


Another example of a "good" hash function is for use with integer key
values, the mean square method. The mean square method squares the key
value and then extracts the average digits of the result, giving a value
in the range from 0 to M. Software implementation of hash function
algorithm creation in Golang language is reduced to the use of built-in
functions of conversion of integers into string (`strconv.Atoi(i)`) and
vice versa (`strc__onv.Itoa(i))`).__ For example, for any four-digit
number, the hash function is:

[source,go]
----
func  hFunc(i,) int {
    var j int
    var s string
    i = i*i
    s = strconv.Itoa(i)
    s = s[3:5]
    j,_ = strconv.Atoi(s)
    return j
}
----

A more realistic scenario in hash table construction involves the phenomenon
known as collision, where multiple keys hash to the same bucket or index. 
In many cases, two or more keys are hashed identically, resulting in their 
mapping to the same slot in the hash table. To handle this situation, there are 
two primary strategies: either locate an alternative entry for the new key or 
maintain a separate list at each index in the hash table to accommodate all keys 
that hash to that index. These approaches represent two classic hashing schemes:


* оpen addressing hashing with linear testing;
* сhain hashing or so-called multidimensional hashing.

However, this topic is outside the scope of this manual.
